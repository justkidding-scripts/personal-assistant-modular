# Personal Assistant MODULAR ğŸ¤–

A comprehensive, modular personal assistant with Discord integration, RAG (Retrieval-Augmented Generation) capabilities, health triage, and more.

## ğŸš€ Features

### ğŸ” **RAG System (Retrieval-Augmented Generation)**
- Advanced document indexing and search
- SQLite backend with Ollama/OpenAI embeddings
- Support for .txt, .md, .json files
- Fallback similarity search system
- Discord file attachment indexing

### ğŸ’¬ **Discord Integration**
- Full Discord bot with slash commands
- File attachment processing
- Interactive commands with reactions
- Both prefix (`!pa`) and slash command support

### ğŸ©º **Health Triage**
- Preliminary health assessment
- Symptom analysis and categorization
- Medical disclaimer compliance
- Emergency guidance

### ğŸ“‹ **Todo Management**
- Task tracking and organization
- Priority management
- Status updates

### ğŸ“„ **Text Summarization**
- Document summarization
- Content analysis

### ğŸŒ **Web API**
- FastAPI-based REST API
- Interactive documentation
- Multiple interface options

### ğŸ–¥ï¸ **CLI Interface**
- Rich terminal interface
- Interactive shell mode
- Command completion

## ğŸ“¦ Installation

### Quick Install
```bash
git clone https://github.com/nike/personal-assistant-modular.git
cd personal-assistant-modular
./install.sh
```

### Manual Installation
```bash
# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
pip install -e .

# Copy environment configuration
cp .env.example .env
# Edit .env with your configurations
```

## âš™ï¸ Configuration

Create a `.env` file with your settings:

```env
# Discord Configuration
DISCORD_TOKEN=your_discord_bot_token_here
DISCORD_GUILD_ID=your_server_id_optional

# Ollama Configuration (Local LLM)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# OpenAI Configuration (Optional)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com
OPENAI_MODEL=gpt-4o-mini

# RAG System
RAG_SRC_PATH=/path/to/advanced/rag/system
```

## ğŸƒâ€â™‚ï¸ Usage

### Discord Bot
```bash
# Start Discord bot
python discord_bot.py
# or
./start_bot.sh
```

**Discord Commands:**
- `!pa ask <question>` - Ask a general question
- `!pa rag_add <path>` - Index files for RAG
- `!pa rag_ask <question>` - Query indexed documents
- `!pa triage <symptoms>` - Health triage assessment
- `/rag_help` - Show RAG usage guide

### CLI Interface
```bash
# Interactive shell
python assistant_cli.py shell

# Direct commands
python assistant_cli.py ask "What's the weather like?"
python assistant_cli.py rag add /path/to/documents
python assistant_cli.py rag ask "What did I index?"
```

### Web API
```bash
# Start FastAPI server
python server.py
# Visit http://localhost:8000/docs for interactive API documentation
```

## ğŸ—ï¸ Architecture

```
PERSONAL-ASSISTANT-MODULAR/
â”œâ”€â”€ ğŸ“ skills/                   # Modular skill system
â”‚   â”œâ”€â”€ ğŸ base.py              # Base skill interface
â”‚   â”œâ”€â”€ ğŸ” rag.py               # RAG implementation
â”‚   â”œâ”€â”€ ğŸ©º health_triage.py     # Health triage system
â”‚   â”œâ”€â”€ ğŸ“‹ todos.py             # Todo management
â”‚   â””â”€â”€ ğŸ“„ summarizer.py        # Text summarization
â”œâ”€â”€ ğŸ¤– assistant.py             # Core assistant logic
â”œâ”€â”€ ğŸ’¬ discord_bot.py           # Discord integration
â”œâ”€â”€ ğŸ–¥ï¸ assistant_cli.py         # CLI interface
â”œâ”€â”€ ğŸŒ server.py                # FastAPI web server
â”œâ”€â”€ ğŸ“„ requirements.txt         # Python dependencies
â”œâ”€â”€ ğŸ”§ setup.py                 # Package configuration
â”œâ”€â”€ ğŸš€ install.sh               # Installation script
â”œâ”€â”€ ğŸ¯ start_bot.sh             # Bot startup script
â””â”€â”€ ğŸ“š README.md                # This file
```

## ğŸ”Œ Skills System

The assistant uses a modular skill system. Each skill inherits from `BaseSkill`:

```python
from skills.base import BaseSkill

class CustomSkill(BaseSkill):
    name = "custom"
    
    def can_handle(self, text: str) -> bool:
        return text.startswith("custom")
    
    def handle(self, text: str) -> str:
        return "Custom response"
```

## ğŸ” RAG System Details

The RAG system supports multiple backends:

### Primary System
- **Storage**: SQLite with vector embeddings
- **Embeddings**: Ollama or OpenAI models
- **Search**: Semantic similarity search

### Fallback System
- **Storage**: In-memory document store
- **Embeddings**: Character frequency analysis
- **Search**: Basic similarity matching

## ğŸ› ï¸ Development

### Adding New Skills
1. Create a new file in `skills/`
2. Inherit from `BaseSkill`
3. Implement `can_handle()` and `handle()` methods
4. Add to `assistant.py` skills list

## ğŸ“„ License

MIT License - see LICENSE file for details

---

**Personal Assistant MODULAR** - Your comprehensive, modular AI assistant solution ğŸš€